{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"builtin.module\"() ({\n",
      "  \"toy.func\"() ({\n",
      "    %0 = \"toy.constant\"() {\"value\" = dense<[[1, 2, 3], [4, 5, 6]]> : tensor<2x3xi32>} : () -> tensor<2x3xi32>\n",
      "    %1 = \"toy.reshape\"(%0) : (tensor<2x3xi32>) -> tensor<2x3xi32>\n",
      "    %2 = \"toy.constant\"() {\"value\" = dense<[1, 2, 3, 4, 5, 6]> : tensor<6xi32>} : () -> tensor<6xi32>\n",
      "    %3 = \"toy.reshape\"(%2) : (tensor<6xi32>) -> tensor<2x3xi32>\n",
      "    %4 = \"toy.add\"(%1, %3) : (tensor<2x3xi32>, tensor<2x3xi32>) -> tensor<2x3xi32>\n",
      "    \"toy.print\"(%4) : (tensor<2x3xi32>) -> ()\n",
      "    \"toy.return\"() : () -> ()\n",
      "  }) {\"sym_name\" = \"main\", \"function_type\" = () -> ()} : () -> ()\n",
      "}) : () -> ()\n",
      "\n",
      "\"builtin.module\"() ({\n",
      "  \"riscv.data_section\"() ({\n",
      "    \"riscv_ssa.label\"() {\"label\" = #riscv.label<main.a>} : () -> ()\n",
      "    \"riscv_ssa.directive\"() {\"directive\" = \".word\", \"value\" = \"0xA, 0x2, 0x2, 0x3, 0x6, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6\"} : () -> ()\n",
      "    \"riscv_ssa.label\"() {\"label\" = #riscv.label<main.b>} : () -> ()\n",
      "    \"riscv_ssa.directive\"() {\"directive\" = \".word\", \"value\" = \"0xA, 0x2, 0x2, 0x3, 0x6, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6\"} : () -> ()\n",
      "  }) : () -> ()\n",
      "  \"riscv_ssa.func\"() ({\n",
      "    %0 = \"riscv_ssa.li\"() {\"immediate\" = #riscv.label<heap>} : () -> #riscv_ssa.reg\n",
      "    %1 = \"riscv_ssa.li\"() {\"immediate\" = #riscv.label<main.a>} : () -> #riscv_ssa.reg\n",
      "    %2 = \"riscv_ssa.li\"() {\"immediate\" = #riscv.label<main.b>} : () -> #riscv_ssa.reg\n",
      "    %3 = \"riscv.toy.add\"(%1, %2, %0) : (#riscv_ssa.reg, #riscv_ssa.reg, #riscv_ssa.reg) -> #riscv_ssa.reg\n",
      "    \"riscv.toy.print\"(%3) : (#riscv_ssa.reg) -> ()\n",
      "    \"riscv_ssa.return\"() : () -> ()\n",
      "  }) {\"func_name\" = \"main\"} : () -> ()\n",
      "}) : () -> ()\n",
      "\n",
      ".bss \n",
      "heap:\n",
      ".space 1024\n",
      ".data \n",
      "main.a:\n",
      ".word 0xA, 0x2, 0x2, 0x3, 0x6, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6\n",
      "main.b:\n",
      ".word 0xA, 0x2, 0x2, 0x3, 0x6, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6\n",
      ".text \n",
      "main:\n",
      "\tli\t%0, heap\n",
      "\tli\t%1, main.a\n",
      "\tli\t%2, main.b\n",
      "\ttoy.add\t%3, %1, %2, %0\n",
      "\ttoy.print\t%3\n",
      "\tli\ta7, 93\n",
      "\tscall\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1m[CPU] Started running from example.asm:.text at heap (0x100) + 0x458\u001b[0m\n",
      "Program(name=example.asm,sections=set(),base=['.bss', '.data', '.text'])\n",
      "\u001b[34m\u001b[1m   Running 0x00000558:\u001b[0m li %0, heap\n",
      "\u001b[34m\u001b[1m   Running 0x0000055C:\u001b[0m li %1, main.a\n",
      "\u001b[34m\u001b[1m   Running 0x00000560:\u001b[0m li %2, main.b\n",
      "\u001b[34m\u001b[1m   Running 0x00000564:\u001b[0m toy.add %3, %1, %2, %0\n",
      "\u001b[34m\u001b[1m   Running 0x00000568:\u001b[0m toy.print %3\n",
      "[[2, 4, 6], [8, 10, 12]]\n",
      "\u001b[34m\u001b[1m   Running 0x0000056C:\u001b[0m li a7, 93\n",
      "\u001b[34m\u001b[1m   Running 0x00000570:\u001b[0m scall \n",
      "\u001b[34m\u001b[1m[CPU] Program exited with code 0\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from xdsl.ir import MLContext, Region, Dialect, SSAValue\n",
    "from xdsl.dialects.builtin import ModuleOp\n",
    "from xdsl.printer import Printer\n",
    "\n",
    "from toy.dialect import Toy\n",
    "from toy.helpers import parse as parse_toy, print_module\n",
    "\n",
    "import riscv.riscv_ssa as riscv_d\n",
    "from riscv.emulator_iop import run_riscv, print_riscv_ssa\n",
    "\n",
    "### WIP\n",
    "\n",
    "example = \"\"\"\n",
    "def main() {\n",
    "  var a<2, 3> = [[1, 2, 3], [4, 5, 6]];\n",
    "  var b<2, 3> = [1, 2, 3, 4, 5, 6];\n",
    "  var c = a + b;\n",
    "  print(c);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "### WIP\n",
    "\n",
    "from xdsl.ir import Operation\n",
    "from xdsl.irdl import irdl_op_definition, Operand, OpResult\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from riscv.riscv_ssa import RegisterType\n",
    "\n",
    "@irdl_op_definition\n",
    "class PrintTensorOp(Operation):\n",
    "    name = \"riscv.toy.print\"\n",
    "    \n",
    "    rs1: Annotated[Operand, RegisterType]\n",
    "    \n",
    "    @classmethod\n",
    "    def get(cls, rs1: Operation | SSAValue) -> PrintTensorOp:\n",
    "        return cls.build(operands=[rs1], result_types=[])\n",
    "\n",
    "@irdl_op_definition\n",
    "class AddTensorOp(Operation):\n",
    "    name = \"riscv.toy.add\"\n",
    "    \n",
    "    rd: Annotated[OpResult, RegisterType]\n",
    "    rs1: Annotated[Operand, RegisterType]\n",
    "    rs2: Annotated[Operand, RegisterType]\n",
    "    rs3: Annotated[Operand, RegisterType]\n",
    "    \n",
    "    @classmethod\n",
    "    def get(cls, lhs_reg: Operation | SSAValue, rhs_reg: Operation | SSAValue, heap_reg: Operation | SSAValue) -> AddTensorOp:\n",
    "        return cls.build(operands=[lhs_reg, rhs_reg, heap_reg], result_types=[RegisterType()])\n",
    "\n",
    "ToyRISCV = Dialect([PrintTensorOp, AddTensorOp], [])\n",
    "\n",
    "### WIP\n",
    "\n",
    "context = MLContext()\n",
    "\n",
    "context.register_dialect(Toy)\n",
    "context.register_dialect(riscv_d.RISCVSSA)\n",
    "context.register_dialect(ToyRISCV)\n",
    "\n",
    "printer = Printer(target=Printer.Target.MLIR)\n",
    "\n",
    "### WIP\n",
    "\n",
    "from riscemu.instructions import InstructionSet, Instruction\n",
    "from riscemu.MMU import MMU\n",
    "from riscemu.types import Int32\n",
    "\n",
    "from typing import cast\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "def tensor_description(shape: list[int], data: list[int]) -> str:\n",
    "    if len(shape) == 1:\n",
    "        return str(data)\n",
    "    if len(shape):\n",
    "        size = reduce(lambda acc, el: acc * el, shape[1:], 1)\n",
    "        return f'[{\", \".join(tensor_description(shape[1:], data[start:start+size]) for start in range(0, size * shape[0], size))}]'\n",
    "    else:\n",
    "        return '[]'\n",
    "\n",
    "# Define a RISC-V ISA extension by subclassing InstructionSet\n",
    "class ToyAccelerator(InstructionSet):\n",
    "    # each method beginning with instruction_ will be available to the Emulator\n",
    "    \n",
    "    def ptr_read(self, ptr: int, /, offset: int = 0) -> int:\n",
    "        mmu = cast(MMU, self.mmu)\n",
    "        byte_array = mmu.read(ptr + offset * 4, 4)\n",
    "        return int.from_bytes(byte_array, byteorder=\"little\")\n",
    "    \n",
    "    def ptr_write(self, ptr: int, /, value: int, offset: int = 0):\n",
    "        mmu = cast(MMU, self.mmu)\n",
    "        byte_array = bytearray(value.to_bytes(4, byteorder=\"little\"))\n",
    "        mmu.write(ptr + offset * 4, 4, byte_array)\n",
    "\n",
    "    def buffer_read(self, ptr: int, len: int, /, offset: int = 0) -> list[int]:\n",
    "        return [\n",
    "            self.ptr_read(ptr, offset) for offset in range(offset, offset+len)\n",
    "        ]\n",
    "\n",
    "    def buffer_write(self, ptr: int, /, data: list[int], offset: int = 0):\n",
    "        for i, value in enumerate(data):\n",
    "            self.ptr_write(ptr, value=value, offset=offset+i)\n",
    "\n",
    "    def buffer_copy(self, /, source: int, destination: int, count: int):\n",
    "        mmu = cast(MMU, self.mmu)\n",
    "        mmu.write(destination, count * 4, mmu.read(source, count * 4))\n",
    "\n",
    "    # Vector helpers\n",
    "\n",
    "    # A vector is represented as an array of ints, where the first int is the count:\n",
    "    # [] -> [0]\n",
    "    # [1] -> [1, 1]\n",
    "    # [1, 2, 3] -> [3, 1, 2, 3]\n",
    "\n",
    "    def vector_count(self, ptr: int) -> int:\n",
    "        return self.ptr_read(ptr)\n",
    "            \n",
    "    def vector_data(self, ptr: int) -> list[int]:\n",
    "        count = self.vector_count(ptr)\n",
    "        return self.buffer_read(ptr, count, offset=1)\n",
    "\n",
    "    def vector_end(self, ptr: int) -> int:\n",
    "        return ptr + (1 + self.ptr_read(ptr)) * 4\n",
    "\n",
    "    def vector_add(self, lhs: int, rhs: int):\n",
    "        '''lhs += rhs'''\n",
    "        count = self.vector_count(lhs)\n",
    "        data = [l + r for (l, r) in zip(self.vector_data(lhs), self.vector_data(rhs))]\n",
    "        self.buffer_write(lhs, data=data, offset=1)\n",
    "\n",
    "    # Heap helpers\n",
    "    \n",
    "    # The heap pointer is the address of the start of the heap, and contains the count\n",
    "    # of remaining allocated elements. Defaults to 0. This means that it can\n",
    "    # be used as an append-only vector.\n",
    "\n",
    "    def alloc(self, heap_ptr: int, /, count: int) -> int:\n",
    "        result = self.vector_end(heap_ptr)\n",
    "        heap_size = self.vector_count(heap_ptr)\n",
    "        self.ptr_write(heap_ptr, value=heap_size + count * 4)\n",
    "        return result\n",
    "\n",
    "    def vector_copy(self, ptr: int, /, heap_ptr: int) -> int:\n",
    "        storage_len = self.vector_count(ptr) + 1\n",
    "        new = self.alloc(heap_ptr, count=storage_len)\n",
    "        self.buffer_copy(source=ptr, destination=new, count=storage_len)\n",
    "        return new\n",
    "\n",
    "    # Tensor helpers\n",
    "\n",
    "    # The tensor is represented as a vector, containing two concatenated vectors:\n",
    "    # the shape, followed by the data\n",
    "    # [] -> [2, 0, 0] (rank: 0, shape: [], count: 0, data: [])\n",
    "    # [1, 2] -> [5, 1, 2, 2, 1, 2] (rank: 1, shape: [2], count: 2, data: [1, 2])\n",
    "    # [[1, 2, 3], [4, 5, 6]] \n",
    "    #   -> [10, 2, 2, 3, 6, 1, 2, 3, 4, 5, 6] (\n",
    "    #       rank: 2, \n",
    "    #       shape: [2, 3], \n",
    "    #       count: 2, \n",
    "    #       data: [1, 2, 3, 4, 5, 6]\n",
    "    #   )\n",
    "\n",
    "    # Where rank is the length of the shape subarray, and count is the length of data.\n",
    "\n",
    "    def tensor_shape_array(self, ptr: int) -> int:\n",
    "        return ptr + 4\n",
    "\n",
    "    def tensor_rank(self, ptr: int) -> int:\n",
    "        return self.vector_count(self.tensor_shape_array(ptr))\n",
    "\n",
    "    def tensor_shape(self, ptr: int) -> list[int]:\n",
    "        return self.vector_data(self.tensor_shape_array(ptr))\n",
    "\n",
    "    def tensor_data_array(self, ptr: int) -> int:\n",
    "        return self.vector_end(self.tensor_shape_array(ptr))\n",
    "\n",
    "    def tensor_count(self, ptr: int):\n",
    "        return self.vector_count(self.tensor_data_array(ptr))\n",
    "\n",
    "    def tensor_data(self, ptr: int) -> list[int]:\n",
    "        return self.vector_data(self.tensor_data_array(ptr))\n",
    "\n",
    "    def tensor_storage_len(self, ptr: int):\n",
    "        '''\n",
    "        rank + count + 2\n",
    "        '''\n",
    "        return self.vector_count(ptr)\n",
    "\n",
    "    def tensor_copy(self, ptr: int, /, heap_ptr: int) -> int:\n",
    "        return self.vector_copy(ptr, heap_ptr=heap_ptr)\n",
    "\n",
    "    def tensor_add(self, lhs: int, rhs: int):\n",
    "        '''lhs += rhs'''\n",
    "        self.vector_add(self.tensor_data_array(lhs), self.tensor_data_array(rhs))\n",
    "\n",
    "    # Custom instructions\n",
    "\n",
    "    def instruction_toy_print(self, ins: Instruction):\n",
    "        \"\"\"\n",
    "        This instruction prints a formatted tensor\n",
    "        [[1, 2, 3], [4, 5, 6]]\n",
    "        \"\"\"\n",
    "        # get the input register\n",
    "        t_ptr_reg = ins.get_reg(0)\n",
    "        t_ptr = int(self.regs.get(t_ptr_reg))\n",
    "\n",
    "        shape = self.tensor_shape(t_ptr)\n",
    "        data = self.tensor_data(t_ptr)\n",
    "        \n",
    "        print(tensor_description(shape, data))\n",
    "\n",
    "    def instruction_toy_add(self, ins: Instruction):\n",
    "        \"\"\"\n",
    "        This instruction allocates a tensor with the same shape as the inputs, and stores\n",
    "        the pointwise sum. No checks about validity of inputs are made.\n",
    "        \"\"\"\n",
    "\n",
    "        destination_ptr_reg = ins.get_reg(0)\n",
    "        lhs_ptr_reg = ins.get_reg(1)\n",
    "        rhs_ptr_reg = ins.get_reg(2)\n",
    "        heap_ptr_reg = ins.get_reg(3)\n",
    "\n",
    "        l_ptr = int(self.regs.get(lhs_ptr_reg))\n",
    "        r_ptr = int(self.regs.get(rhs_ptr_reg))\n",
    "        h_ptr = int(self.regs.get(heap_ptr_reg))\n",
    "        \n",
    "        l_shape = self.tensor_shape(l_ptr)\n",
    "        r_shape = self.tensor_shape(r_ptr)\n",
    "\n",
    "        assert l_shape == r_shape\n",
    "\n",
    "        d_ptr = self.tensor_copy(l_ptr, heap_ptr=h_ptr)\n",
    "        self.tensor_add(d_ptr, r_ptr)\n",
    "\n",
    "        self.regs.set(destination_ptr_reg, Int32(d_ptr))\n",
    "\n",
    "\n",
    "### WIP\n",
    "\n",
    "module = parse_toy(example)\n",
    "print_module(module)\n",
    "print()\n",
    "\n",
    "### WIP\n",
    "\n",
    "module = ModuleOp.from_region_or_ops([\n",
    "    riscv_d.DataSectionOp.from_ops([\n",
    "        riscv_d.LabelOp.get(\"main.a\"),\n",
    "        riscv_d.DirectiveOp.get(\".word\", \"0xA, 0x2, 0x2, 0x3, 0x6, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6\"),\n",
    "        riscv_d.LabelOp.get(\"main.b\"),\n",
    "        riscv_d.DirectiveOp.get(\".word\", \"0xA, 0x2, 0x2, 0x3, 0x6, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6\"),\n",
    "    ]),\n",
    "    riscv_d.FuncOp.from_ops('main', [\n",
    "        heap := riscv_d.LIOp.get('heap'),\n",
    "        a := riscv_d.LIOp.get('main.a'),\n",
    "        b := riscv_d.LIOp.get('main.b'),\n",
    "        c := AddTensorOp.get(a, b, heap),\n",
    "        PrintTensorOp.get(c),\n",
    "        riscv_d.ReturnOp.get(),\n",
    "    ])\n",
    "])\n",
    "\n",
    "print_module(module)\n",
    "print()\n",
    "\n",
    "### WIP\n",
    "\n",
    "code = print_riscv_ssa(module)\n",
    "print(code)\n",
    "print()\n",
    "\n",
    "### WIP\n",
    "\n",
    "import contextlib, io\n",
    "\n",
    "f = io.StringIO()\n",
    "with contextlib.redirect_stdout(f):\n",
    "    run_riscv(code, extensions=[ToyAccelerator], unlimited_regs=True)\n",
    "output = f.getvalue()\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c189b674810d96af66833b07bd9a3fc1b15f37c11bf66e9bb86bed0f17aed6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
