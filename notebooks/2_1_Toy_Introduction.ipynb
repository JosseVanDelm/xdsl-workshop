{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dff794f",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"text-align: center\">\n",
    "<span style=\"\">\n",
    "    <a href=\"0_Table_of_Contents.ipynb\">Table Of Contents üè†</a>\n",
    "</span>\n",
    "<span style=\"float: right\">\n",
    "    <a href=\"2_2_Toy_IR.ipynb\">Next Chapter &gt;</a>\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56341c66",
   "metadata": {},
   "source": [
    "# Chapter 1: Toy Language and AST\n",
    "\n",
    "This is an xDSL version of the Toy compiler, as described in the \n",
    "[MLIR tutorial](https://mlir.llvm.org/docs/Tutorials/Toy/). This, and the following\n",
    "series of notebooks are taken close to word-for-word verbatim from the MLIR tutorials,\n",
    "as the xDSL project mirrors the MLIR structure very closely. We hope that by using these\n",
    "tutorials you will get a better idea of both now to use xDSL, and how MLIR works.\n",
    "\n",
    "## The Language\n",
    "\n",
    "This tutorial will be illustrated with a toy language that we‚Äôll call ‚ÄúToy‚Äù\n",
    "(naming is hard...). Toy is a tensor-based language that allows you to define\n",
    "functions, perform some math computation, and print results.\n",
    "\n",
    "Given that we want to keep things simple, the codegen will be limited to tensors\n",
    "of rank <= 2, and the only datatype in Toy is a 64-bit floating point type (aka\n",
    "‚Äòdouble‚Äô in C parlance). As such, all values are implicitly double precision,\n",
    "`Values` are immutable (i.e. every operation returns a newly allocated value),\n",
    "and deallocation is automatically managed. But enough with the long description;\n",
    "nothing is better than walking through an example to get a better understanding:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e07ae44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_0 = \"\"\"\n",
    "def main() {\n",
    "  var a<2, 3> = [[1, 2, 3], [4, 5, 6]];\n",
    "  var b<6> = [1, 2, 3, 4, 5, 6];\n",
    "  var c<2, 3> = b;\n",
    "  var d = a + c;\n",
    "  print(d);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e14dd76",
   "metadata": {},
   "source": [
    "Type checking is statically performed through type inference; the language only\n",
    "requires type declarations to specify tensor shapes when needed. Functions are\n",
    "generic: their parameters are unranked (in other words, we know these are\n",
    "tensors, but we don't know their dimensions). They are specialized for every\n",
    "newly discovered signature at call sites. Let's revisit the previous example by\n",
    "adding a user-defined function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853ca52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".bss \n",
      "heap:\n",
      ".space 1024\n",
      ".data \n",
      "main.tensor_shape.0:\n",
      ".word 0x2, 0x2, 0x3\n",
      "main.tensor_data.0:\n",
      ".word 0x6, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6\n",
      ".text \n",
      "main:\n",
      "\tli\t%0, heap\n",
      "\tli\t%1, main.tensor_shape.0\n",
      "\tli\t%2, main.tensor_data.0\n",
      "\tli\t%3, 2\n",
      "\tbuffer.alloc\t%4, %3\n",
      "\tsw\t%1, %4, 0\t\t# Set tensor shape\n",
      "\tlw\t%5, %4, 0\n",
      "\tsw\t%2, %4, 4\t\t# Set tensor data\n",
      "\ttoy.print\t%4\n",
      "\tli\ta7, 93\n",
      "\tscall\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1m[CPU] Started running from example.asm:.text at heap (0x100) + 0x428\u001b[0m\n",
      "Program(name=example.asm,sections=set(),base=['.bss', '.data', '.text'])\n",
      "\u001b[34m\u001b[1m   Running 0x00000528:\u001b[0m li %0, heap\n",
      "\u001b[34m\u001b[1m   Running 0x0000052C:\u001b[0m li %1, main.tensor_shape.0\n",
      "\u001b[34m\u001b[1m   Running 0x00000530:\u001b[0m li %2, main.tensor_data.0\n",
      "\u001b[34m\u001b[1m   Running 0x00000534:\u001b[0m li %3, 2\n",
      "\u001b[34m\u001b[1m   Running 0x00000538:\u001b[0m buffer.alloc %4, %3\n",
      "\u001b[34m\u001b[1m   Running 0x0000053C:\u001b[0m sw %1, %4, 0\n",
      "\u001b[34m\u001b[1m   Running 0x00000540:\u001b[0m lw %5, %4, 0\n",
      "\u001b[34m\u001b[1m   Running 0x00000544:\u001b[0m sw %2, %4, 4\n",
      "\u001b[34m\u001b[1m   Running 0x00000548:\u001b[0m toy.print %4\n",
      "[[1, 2, 3], [4, 5, 6]]\n",
      "\u001b[34m\u001b[1m   Running 0x0000054C:\u001b[0m li a7, 93\n",
      "\u001b[34m\u001b[1m   Running 0x00000550:\u001b[0m scall \n",
      "\u001b[34m\u001b[1m[CPU] Program exited with code 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from compiler import compile, emulate_riscv\n",
    "\n",
    "program = \"\"\"\n",
    "def main() {\n",
    "  var a<2, 3> = [[1, 2, 3], [4, 5, 6]];\n",
    "  var b<6> = [1, 2, 3, 4, 5, 6];\n",
    "  var c<2, 3> = b;\n",
    "  var d = a + c;\n",
    "  print(a);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "code = compile(program)\n",
    "\n",
    "print(code)\n",
    "print()\n",
    "\n",
    "emulate_riscv(code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "025718ef",
   "metadata": {},
   "source": [
    "The code for the lexer is fairly straightforward; it is all in a single file:\n",
    "`toy/lexer.py`. The parser can be found in `toy/parser.py`; it is a recursive \n",
    "descent parser. If you are not familiar with such a Lexer/Parser, these are very similar \n",
    "to the LLVM Kaleidoscope equivalent that are detailed in the first two chapters of the\n",
    "[LLVM Kaleidoscope Tutorial](https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.html).\n",
    "\n",
    "The next chapter will demonstrate how to convert this AST into MLIR."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d7e7dca",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"text-align: center\">\n",
    "<span style=\"\">\n",
    "    <a href=\"0_Table_of_Contents.ipynb\">Table Of Contents üè†</a>\n",
    "</span>\n",
    "<span style=\"float: right\">\n",
    "    <a href=\"2_2_Toy_IR.ipynb\">Next Chapter &gt;</a>\n",
    "</span>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c189b674810d96af66833b07bd9a3fc1b15f37c11bf66e9bb86bed0f17aed6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
