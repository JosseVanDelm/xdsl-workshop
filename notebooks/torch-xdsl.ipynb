{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing a torch model in MLIR Syntax\n",
    "\n",
    "Those can already be generated by [Torch-MLIR](https://github.com/llvm/torch-mlir)!\n",
    "\n",
    "Let's just parse it and print it for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "builtin.module() [\"torch.debug_module_name\" = \"AlexNet\"] {\n",
      "  func.func() [\"function_type\" = !fun<[!torch.vtensor<[1 : !i64, 3 : !i64, 224 : !i64, 224 : !i64], !f32>], [!torch.vtensor<[1 : !i64, 1000 : !i64], !f32>]>, \"sym_name\" = \"forward\"] {\n",
      "  ^0(%0 : !torch.vtensor<[1 : !i64, 3 : !i64, 224 : !i64, 224 : !i64], !f32>):\n",
      "    %1 : !torch.int = torch.constant.int() [\"value\" = 0 : !i64]\n",
      "    %2 : !torch.int = torch.constant.int() [\"value\" = 1 : !i64]\n",
      "    %3 : !torch.float = torch.constant.float() [\"value\" = 1.0 : !f64]\n",
      "    %4 : !torch.int = torch.constant.int() [\"value\" = -1 : !i64]\n",
      "    %5 : !torch.bool = torch.constant.bool() [\"value\" = true]\n",
      "    %6 : !torch.bool = torch.constant.bool() [\"value\" = false]\n",
      "    %7 : !torch.none = torch.constant.none()\n",
      "    %8 : !torch.vtensor<[1000 : !i64, 4096 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[1000 : !index, 4096 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %9 : !torch.vtensor<[1000 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[1000 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %10 : !torch.vtensor<[4096 : !i64, 4096 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[4096 : !index, 4096 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %11 : !torch.vtensor<[4096 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[4096 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %12 : !torch.vtensor<[4096 : !i64, 9216 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[4096 : !index, 9216 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %13 : !torch.vtensor<[4096 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[4096 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %14 : !torch.vtensor<[256 : !i64, 256 : !i64, 3 : !i64, 3 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[256 : !index, 256 : !index, 3 : !index, 3 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %15 : !torch.vtensor<[256 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[256 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %16 : !torch.vtensor<[256 : !i64, 384 : !i64, 3 : !i64, 3 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[256 : !index, 384 : !index, 3 : !index, 3 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %17 : !torch.vtensor<[256 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[256 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %18 : !torch.vtensor<[384 : !i64, 192 : !i64, 3 : !i64, 3 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[384 : !index, 192 : !index, 3 : !index, 3 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %19 : !torch.vtensor<[384 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[384 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %20 : !torch.vtensor<[192 : !i64, 64 : !i64, 5 : !i64, 5 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[192 : !index, 64 : !index, 5 : !index, 5 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %21 : !torch.vtensor<[192 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[192 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %22 : !torch.vtensor<[64 : !i64, 3 : !i64, 11 : !i64, 11 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[64 : !index, 3 : !index, 11 : !index, 11 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %23 : !torch.vtensor<[64 : !i64], !f32> = torch.vtensor.literal() [\"value\" = !dense<!tensor<[64 : !index], !f32>, [1.0 : !f32]>]\n",
      "    %24 : !torch.int = torch.constant.int() [\"value\" = 4 : !i64]\n",
      "    %25 : !torch.int = torch.constant.int() [\"value\" = 2 : !i64]\n",
      "    %26 : !torch.int = torch.constant.int() [\"value\" = 3 : !i64]\n",
      "    %27 : !torch.list<!torch.int> = torch.prim.ListConstruct(%24 : !torch.int, %24 : !torch.int)\n",
      "    %28 : !torch.list<!torch.int> = torch.prim.ListConstruct(%25 : !torch.int, %25 : !torch.int)\n",
      "    %29 : !torch.list<!torch.int> = torch.prim.ListConstruct(%2 : !torch.int, %2 : !torch.int)\n",
      "    %30 : !torch.list<!torch.int> = torch.prim.ListConstruct(%1 : !torch.int, %1 : !torch.int)\n",
      "    %31 : !torch.vtensor<[1 : !i64, 64 : !i64, 55 : !i64, 55 : !i64], !f32> = torch.aten.convolution(%0 : !torch.vtensor<[1 : !i64, 3 : !i64, 224 : !i64, 224 : !i64], !f32>, %22 : !torch.vtensor<[64 : !i64, 3 : !i64, 11 : !i64, 11 : !i64], !f32>, %23 : !torch.vtensor<[64 : !i64], !f32>, %27 : !torch.list<!torch.int>, %28 : !torch.list<!torch.int>, %29 : !torch.list<!torch.int>, %6 : !torch.bool, %30 : !torch.list<!torch.int>, %2 : !torch.int)\n",
      "    %32 : !torch.vtensor<[1 : !i64, 64 : !i64, 55 : !i64, 55 : !i64], !f32> = torch.aten.relu(%31 : !torch.vtensor<[1 : !i64, 64 : !i64, 55 : !i64, 55 : !i64], !f32>)\n",
      "    %33 : !torch.list<!torch.int> = torch.prim.ListConstruct(%26 : !torch.int, %26 : !torch.int)\n",
      "    %34 : !torch.vtensor<[1 : !i64, 64 : !i64, 27 : !i64, 27 : !i64], !f32> = torch.aten.max_pool2d(%32 : !torch.vtensor<[1 : !i64, 64 : !i64, 55 : !i64, 55 : !i64], !f32>, %33 : !torch.list<!torch.int>, %28 : !torch.list<!torch.int>, %30 : !torch.list<!torch.int>, %29 : !torch.list<!torch.int>, %6 : !torch.bool)\n",
      "    %35 : !torch.vtensor<[1 : !i64, 192 : !i64, 27 : !i64, 27 : !i64], !f32> = torch.aten.convolution(%34 : !torch.vtensor<[1 : !i64, 64 : !i64, 27 : !i64, 27 : !i64], !f32>, %20 : !torch.vtensor<[192 : !i64, 64 : !i64, 5 : !i64, 5 : !i64], !f32>, %21 : !torch.vtensor<[192 : !i64], !f32>, %29 : !torch.list<!torch.int>, %28 : !torch.list<!torch.int>, %29 : !torch.list<!torch.int>, %6 : !torch.bool, %30 : !torch.list<!torch.int>, %2 : !torch.int)\n",
      "    %36 : !torch.vtensor<[1 : !i64, 192 : !i64, 27 : !i64, 27 : !i64], !f32> = torch.aten.relu(%35 : !torch.vtensor<[1 : !i64, 192 : !i64, 27 : !i64, 27 : !i64], !f32>)\n",
      "    %37 : !torch.vtensor<[1 : !i64, 192 : !i64, 13 : !i64, 13 : !i64], !f32> = torch.aten.max_pool2d(%36 : !torch.vtensor<[1 : !i64, 192 : !i64, 27 : !i64, 27 : !i64], !f32>, %33 : !torch.list<!torch.int>, %28 : !torch.list<!torch.int>, %30 : !torch.list<!torch.int>, %29 : !torch.list<!torch.int>, %6 : !torch.bool)\n",
      "    %38 : !torch.vtensor<[1 : !i64, 384 : !i64, 13 : !i64, 13 : !i64], !f32> = torch.aten.convolution(%37 : !torch.vtensor<[1 : !i64, 192 : !i64, 13 : !i64, 13 : !i64], !f32>, %18 : !torch.vtensor<[384 : !i64, 192 : !i64, 3 : !i64, 3 : !i64], !f32>, %19 : !torch.vtensor<[384 : !i64], !f32>, %29 : !torch.list<!torch.int>, %29 : !torch.list<!torch.int>, %29 : !torch.list<!torch.int>, %6 : !torch.bool, %30 : !torch.list<!torch.int>, %2 : !torch.int)\n",
      "    %39 : !torch.vtensor<[1 : !i64, 384 : !i64, 13 : !i64, 13 : !i64], !f32> = torch.aten.relu(%38 : !torch.vtensor<[1 : !i64, 384 : !i64, 13 : !i64, 13 : !i64], !f32>)\n",
      "    %40 : !torch.vtensor<[1 : !i64, 256 : !i64, 13 : !i64, 13 : !i64], !f32> = torch.aten.convolution(%39 : !torch.vtensor<[1 : !i64, 384 : !i64, 13 : !i64, 13 : !i64], !f32>, %16 : !torch.vtensor<[256 : !i64, 384 : !i64, 3 : !i64, 3 : !i64], !f32>, %17 : !torch.vtensor<[256 : !i64], !f32>, %29 : !torch.list<!torch.int>, %29 : !torch.list<!torch.int>, %29 : !torch.list<!torch.int>, %6 : !torch.bool, %30 : !torch.list<!torch.int>, %2 : !torch.int)\n",
      "    %41 : !torch.vtensor<[1 : !i64, 256 : !i64, 13 : !i64, 13 : !i64], !f32> = torch.aten.relu(%40 : !torch.vtensor<[1 : !i64, 256 : !i64, 13 : !i64, 13 : !i64], !f32>)\n",
      "    %42 : !torch.vtensor<[1 : !i64, 256 : !i64, 13 : !i64, 13 : !i64], !f32> = torch.aten.convolution(%41 : !torch.vtensor<[1 : !i64, 256 : !i64, 13 : !i64, 13 : !i64], !f32>, %14 : !torch.vtensor<[256 : !i64, 256 : !i64, 3 : !i64, 3 : !i64], !f32>, %15 : !torch.vtensor<[256 : !i64], !f32>, %29 : !torch.list<!torch.int>, %29 : !torch.list<!torch.int>, %29 : !torch.list<!torch.int>, %6 : !torch.bool, %30 : !torch.list<!torch.int>, %2 : !torch.int)\n",
      "    %43 : !torch.vtensor<[1 : !i64, 256 : !i64, 13 : !i64, 13 : !i64], !f32> = torch.aten.relu(%42 : !torch.vtensor<[1 : !i64, 256 : !i64, 13 : !i64, 13 : !i64], !f32>)\n",
      "    %44 : !torch.vtensor<[1 : !i64, 256 : !i64, 6 : !i64, 6 : !i64], !f32> = torch.aten.max_pool2d(%43 : !torch.vtensor<[1 : !i64, 256 : !i64, 13 : !i64, 13 : !i64], !f32>, %33 : !torch.list<!torch.int>, %28 : !torch.list<!torch.int>, %30 : !torch.list<!torch.int>, %29 : !torch.list<!torch.int>, %6 : !torch.bool)\n",
      "    torch.runtime.assert(%5 : !torch.bool) [\"message\" = \"unimplemented: only support cases where input and output size are equal for non-unit output size\"]\n",
      "    torch.runtime.assert(%5 : !torch.bool) [\"message\" = \"unimplemented: only support cases where input and output size are equal for non-unit output size\"]\n",
      "    %45 : !torch.list<!torch.int> = torch.prim.ListConstruct(%2 : !torch.int, %2 : !torch.int)\n",
      "    %46 : !torch.list<!torch.int> = torch.prim.ListConstruct(%2 : !torch.int, %2 : !torch.int)\n",
      "    %47 : !torch.list<!torch.int> = torch.prim.ListConstruct(%1 : !torch.int, %1 : !torch.int)\n",
      "    %48 : !torch.vtensor<[1 : !i64, 256 : !i64, 6 : !i64, 6 : !i64], !f32> = torch.aten.avg_pool2d(%44 : !torch.vtensor<[1 : !i64, 256 : !i64, 6 : !i64, 6 : !i64], !f32>, %45 : !torch.list<!torch.int>, %46 : !torch.list<!torch.int>, %47 : !torch.list<!torch.int>, %6 : !torch.bool, %5 : !torch.bool, %7 : !torch.none)\n",
      "    %49 : !torch.list<!torch.int> = torch.prim.ListConstruct(%2 : !torch.int, %4 : !torch.int)\n",
      "    %50 : !torch.vtensor<[1 : !i64, 9216 : !i64], !f32> = torch.aten.view(%48 : !torch.vtensor<[1 : !i64, 256 : !i64, 6 : !i64, 6 : !i64], !f32>, %49 : !torch.list<!torch.int>)\n",
      "    %51 : !torch.vtensor<[9216 : !i64, 4096 : !i64], !f32> = torch.aten.transpose.int(%12 : !torch.vtensor<[4096 : !i64, 9216 : !i64], !f32>, %1 : !torch.int, %2 : !torch.int)\n",
      "    %52 : !torch.vtensor<[1 : !i64, 4096 : !i64], !f32> = torch.aten.mm(%50 : !torch.vtensor<[1 : !i64, 9216 : !i64], !f32>, %51 : !torch.vtensor<[9216 : !i64, 4096 : !i64], !f32>)\n",
      "    %53 : !torch.vtensor<[1 : !i64, 4096 : !i64], !f32> = torch.aten.add.Tensor(%52 : !torch.vtensor<[1 : !i64, 4096 : !i64], !f32>, %13 : !torch.vtensor<[4096 : !i64], !f32>, %3 : !torch.float)\n",
      "    %54 : !torch.vtensor<[1 : !i64, 4096 : !i64], !f32> = torch.aten.relu(%53 : !torch.vtensor<[1 : !i64, 4096 : !i64], !f32>)\n",
      "    %55 : !torch.vtensor<[4096 : !i64, 4096 : !i64], !f32> = torch.aten.transpose.int(%10 : !torch.vtensor<[4096 : !i64, 4096 : !i64], !f32>, %1 : !torch.int, %2 : !torch.int)\n",
      "    %56 : !torch.vtensor<[1 : !i64, 4096 : !i64], !f32> = torch.aten.mm(%54 : !torch.vtensor<[1 : !i64, 4096 : !i64], !f32>, %55 : !torch.vtensor<[4096 : !i64, 4096 : !i64], !f32>)\n",
      "    %57 : !torch.vtensor<[1 : !i64, 4096 : !i64], !f32> = torch.aten.add.Tensor(%56 : !torch.vtensor<[1 : !i64, 4096 : !i64], !f32>, %11 : !torch.vtensor<[4096 : !i64], !f32>, %3 : !torch.float)\n",
      "    %58 : !torch.vtensor<[1 : !i64, 4096 : !i64], !f32> = torch.aten.relu(%57 : !torch.vtensor<[1 : !i64, 4096 : !i64], !f32>)\n",
      "    %59 : !torch.vtensor<[4096 : !i64, 1000 : !i64], !f32> = torch.aten.transpose.int(%8 : !torch.vtensor<[1000 : !i64, 4096 : !i64], !f32>, %1 : !torch.int, %2 : !torch.int)\n",
      "    %60 : !torch.vtensor<[1 : !i64, 1000 : !i64], !f32> = torch.aten.mm(%58 : !torch.vtensor<[1 : !i64, 4096 : !i64], !f32>, %59 : !torch.vtensor<[4096 : !i64, 1000 : !i64], !f32>)\n",
      "    %61 : !torch.vtensor<[1 : !i64, 1000 : !i64], !f32> = torch.aten.add.Tensor(%60 : !torch.vtensor<[1 : !i64, 1000 : !i64], !f32>, %9 : !torch.vtensor<[1000 : !i64], !f32>, %3 : !torch.float)\n",
      "    func.return(%61 : !torch.vtensor<[1 : !i64, 1000 : !i64], !f32>)\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from torch.dialect import Torch\n",
    "from xdsl.dialects.func import Func\n",
    "from xdsl.dialects.builtin import Builtin\n",
    "from xdsl.parser import Parser, Source\n",
    "from xdsl.printer import Printer\n",
    "from xdsl.ir import MLContext\n",
    "\n",
    "context = MLContext()\n",
    "context.register_dialect(Torch)\n",
    "context.register_dialect(Func)\n",
    "context.register_dialect(Builtin)\n",
    "\n",
    "with open('examples/alexnet.mlir')as f:\n",
    "    parser = Parser(context, f.read(), Source.MLIR, f.name)\n",
    "    module = parser.parse_module()\n",
    "\n",
    "printer = Printer()\n",
    "\n",
    "printer.print(module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d6790b426e2d71827724f01810f2f8f578a9246b0feca7b7fe6fc65e1a78cd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
